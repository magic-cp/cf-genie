# cf-genie

Tesis de grado para optar al t铆tulo de Ingenier铆a de la Computaci贸n en la Universidad Sim贸n Bol铆var

# Instalacion

Como cualquier proyecto de python, primero hay que configurar un ambiente virtual. Luego de crearlo y activarlo, hay que correr el siguiente comando para instalar
las dependencias escenciales:

```shell
pip install -r requirements.txt
```

Si deseas desarrollar, debes insetalar las dependencias de desarrollo:

```shell
pip install -r dev_requirements.txt
```

# Uso

Hay varios m贸dulos, y todos se corren de la siguiente manera:

```shell
python -m cf_genie.tasks.<nombre del task>
```

Para ver la lista completa de tasks, ver los archivos dentro de [./cf_genie/tasks](./cf_genie/tasks)

# Setup inicial

Para recrear toda la data para entrenar los modelos, hay que ejecutar los siguientes scripts, en este orden:

1. `load_cf_data`
2. `generate_temp_input_for_raw_dataset`
3. `scrap_dataset`
4. `cleanup_dataset_task`

Entre (3) y (4) hay que mover el archivo `temp/raw_dataset_file.csv` a `dataset/raw_cf_problems.csv`.

# Ejecucion

Usamos `hyperopt` para la hiper-parametrizacion de nuestros modelos. Todas las combinaciones realizadas son guardadas en una base de datos de mongo. Para facilitar el setup del proyecto, se a帽adi贸 `docker-compose.yml` que permite construir un contenedor de docker con un volumen persistente para guardar los resultados de todas las ejecuciones.

Para levantar el container de docker, solo hay que levantar la red con:

```shell
docker-compose up -d
```

> 癸 Sobre `mongo-express`
>
> Incluido en la red esta un contenedor de `mongo-express`, que es un cliente web sencillo para consultar la base de datos. Se puede acceder a este cliente en `localhost:8081`

El mongodb path para conectarse seria `mongo://localhost:27017/admin/jobs`. No hay autenticacion en este esquema (no hace falta!).

Luego, hay que correr el m贸dulo de Python donde se hace la hyper-parametrizaci贸n con `hyperopt`. Al ejecutarlo, el m贸dulo va a quedarse "idle": lo que ocurre es que se van a generar documentos en MongoDB, donde cada uno tiene la informacion necesaria para generar el modelo (algoritmo de aprendizaje + parametros), pero no va a entrenar ningun modelo.

Para empezar el entrenamiento en paralelo, hay que iniciar los workers. Para iniciar un (y solo un) worker, hay que ejecutar el siguiente comando:

```bash
./hyperopt-worker.sh
```

Si quieres tener N workers, hay que correr este worker N veces en N sesiones de terminal distintas.

Cada worker va a operar de la siguiente manera:

1. Se escoge un documento de MongoDB que no se haya evaluado. Cada documento tiene la informaci贸n necesaria para poder evaluar la funci贸n
2. Cuando el worker termina de entrenar el modelo, va a actualizar el documento con los resultados (usualmente el score y el modelo serializado con `pickle`)

>  Se puede tener una instancia de MongoDB en la nube, y tener varios workers como maquinas dedicaddas para poder acelerar el proceso. Stonks 
